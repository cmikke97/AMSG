[sorel20mDataset]
# max number of training data samples to use (if -1 -> takes all), default: 6000000
training_n_samples = 6000000
# max number of validation data samples to use (if -1 -> takes all), default: 1153846
validation_n_samples = 1153846
# max number of test data samples to use (if -1 -> takes all), default: 1846154
test_n_samples = 1846154

# This is the timestamp that divides the validation data (used to check convergence/overfitting)
# from test data (used to assess final performance)
validation_test_split = 1547279640.0
# This is the timestamp that splits training data from validation data
train_validation_split = 1543542570.0
# total number of available samples in the original Sorel20M dataset
total_training_samples = 12699013
total_validation_samples = 2495822
total_test_samples = 4195042

[detectionBase]
# set this to the desired device, e.g. 'cuda:0' if a GPU is available, otherwise 'cpu'
device = cuda:0

workers = 8

# number of training runs to do
runs = 2
# how many samples per batch to load # 8192
batch_size = 8192
# how many epochs to train for
epochs = 10

# whether or not to use malware/benignware labels as a target
use_malicious_labels = 1
# whether or not to use the counts as an additional target
use_count_labels = 1
# whether or not to use the tags as additional targets
use_tag_labels = 1

# define detectionBase net initial linear layers sizes (and amount). Examples:
# - [512,512,128]: the initial layers (before the task branches) will be 3 with sizes 512, 512, 128 respectively
# - [512,256]: the initial layers (before the task branches) will be 2 with sizes 512, 256 respectively
layer_sizes=[512,512,128]

# dropout probability between the first detectionBase net layers
dropout_p=0.05

# activation function between the first detectionBase net layers. Possible values:
# - elu: Exponential Linear Unit activation function
# - leakyRelu: leaky Relu activation function
# - pRelu: parametric Relu activation function (better to use this with weight decay = 0)
# - relu: Rectified Linear Unit activation function
activation_function = elu

# label weights to be used during loss calculation
# (Notice: only the weights corresponding to enabled labels will be used)
loss_weights = {'malware': 1.0, 'count': 0.1, 'tags': 1.0}

# optimizer to use during training. Possible values:
# - adam: Adam algorithm
# - sgd: stochastic gradient descent
optimizer = 'adam'

# learning rate to use during training
lr = 0.001

# momentum to be used during training when using 'sgd' optimizer.
momentum = 0.0

# weight decay (L2 penalty) to use with selected optimizer
weight_decay = 0.0

# generator type. Possible values are:
# - base: use basic generator (from the original SOREL20M code) modified to work with the pre-processed dataset
# - alt1: use alternative generator 1. Inspired by the 'index select' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing).
# - alt2: use alternative generator 2. Inspired by the 'shuffle in-place' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing).
# - alt3: use alternative generator 3. Inspired by the 'shuffle in-place' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing). Furthermore, the dataset is loaded into memory in randomly
#         chosen chunks -> samples are randomly chosen from the loaded chunks. Therefore the samples shuffling is more
#         localised but the speed should be increased.
gen_type = alt3

[jointEmbedding]
# set this to the desired device, e.g. 'cuda:0' if a GPU is available, otherwise 'cpu'
device = cuda:0

workers = 8

# number of training runs to do
runs = 2
# how many samples per batch to load # 8192
batch_size = 8192
# how many epochs to train for
epochs = 10

# whether or not to use malware/benignware labels as a target
use_malicious_labels = 1
# whether or not to use the counts as an additional target
use_count_labels = 1

# define JointEmbedding net initial linear layers sizes (and amount). Examples:
# - [512,512,128]: the initial layers (before the task branches) will be 3 with sizes 512, 512, 128 respectively
# - [512,256]: the initial layers (before the task branches) will be 2 with sizes 512, 256 respectively
layer_sizes=[512,512,128]

# dropout probability between the first JointEmbedding net layers
dropout_p=0.05

# activation function between the first detectionBase net layers. Possible values:
# - elu: Exponential Linear Unit activation function
# - leakyRelu: leaky Relu activation function
# - pRelu: parametric Relu activation function (better to use this with weight decay = 0)
# - relu: Rectified Linear Unit activation function
activation_function = elu

# label weights to be used during loss calculation
# (Notice: only the weights corresponding to enabled labels will be used)
loss_weights = {'malware': 1.0, 'count': 0.1, 'tags': 1.0}

# optimizer to use during training. Possible values:
# - adam: Adam algorithm
# - sgd: stochastic gradient descent
optimizer = 'adam'

# learning rate to use during training
lr = 0.001

# momentum to be used during training when using 'sgd' optimizer.
momentum = 0.0

# weight decay (L2 penalty) to use with selected optimizer
weight_decay = 0.0

# generator type. Possible values are:
# - base: use basic generator (from the original SOREL20M code) modified to work with the pre-processed dataset
# - alt1: use alternative generator 1. Inspired by the 'index select' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing).
# - alt2: use alternative generator 2. Inspired by the 'shuffle in-place' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing).
# - alt3: use alternative generator 3. Inspired by the 'shuffle in-place' version of
#         https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6, this version uses a new
#         dataloader class, called FastTensorDataloader, to process tabular based data. It was modified from the
#         original version available at the above link to be able to work with the pre-processed dataset (numpy memmap)
#         and with multiple workers (in multiprocessing). Furthermore, the dataset is loaded into memory in randomly
#         chosen chunks -> samples are randomly chosen from the loaded chunks. Therefore the samples shuffling is more
#         localised but the speed should be increased.
gen_type = alt3

# similarity measure used to evaluate distances in joint embedding space. Possible values are:
# - dot: dot product between vectors in the embedding space. The similarity measure used in JointEmbedding paper.
# - cosine: cosine similarity between vectors in the embedding space.
# - pairwise_distance: calculates the pairwise distance and then transforms it to a similarity measure (between 0 and 1)
similarity_measure = dot

# + IF 'pairwise_distance' IS SELECTED AS similarity_measure -----------------------------------------------------------
# |
# | distance-to-similarity function to use. These functions will map values belonging to the R+ set (Real positives) to
# | real values belonging to the [0,1] interval. Possible values are:
# | - exp: will compute e^(-x/a)
# | - inv: will compute 1/(1+x/a)
# | - inv_pow: will compute 1/(1+(x^2)/a)
# | where 'a' is a multiplicative factor (it is set to be equal to the embedding feature dimension).
pairwise_distance_to_similarity_function = exp
# + --------------------------------------------------------------------------------------------------------------------

[freshDataset]
# Specify Malware Bazaar families of interest.
# NOTE: It is recommended to specify more families than 'number_of_families' since Malware Bazaar may not have
# 'amount_each' samples for some of them. These families will be considered in order.

# Taken from https://cert-agid.gov.it/news/riepilogo-delle-campagne-malevole-che-hanno-interessato-litalia-nellultimo-quadrimestre-2020/
signatures = Gozi,Heodo,Dridex,AgentTesla,FormBook,MassLogger,Loki,Quakbot,AveMariaRAT,Mekotio,Qrat,ASTesla,QNodeService,njrat,RemcosRAT,ZLoader,XpertRat,NetWire,CoinMiner.XMRig,Alien,AZORult,Neshta,Ostap,Smoke Loader,Matiex,Dharma,AsyncRAT,QarallaxRAT
# Number of families to consider. The ones in excess, going in order, will not be considered.
number_of_families = 10
# Amount of samples for each malware family to retrieve from Malware Bazaar
amount_each = 100

# Number of queries to do in model evaluation
queries = 100

# Alternative families (combining info taken from https://cert-agid.gov.it/news/sintesi-riepilogativa-delle-campagne-malevole-nella-settimana-24-30-aprile-2021/ and https://bazaar.abuse.ch/statistics/)
# signatures = Heodo,Quakbot,AgentTesla,Dridex,FormBook,CobaltStrike,Loki,Gozi,GuLoader,Trickbot,RaccoonStealer,DarkSide,RemcosRAT,SnakeKeylogger,GandCrab,njrat,AveMariaRAT,AZORult,NanoCore