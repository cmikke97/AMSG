{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DetectionBase_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP6HuV2wejQJdZ4V8q1ybUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmikke97/Automatic-Malware-Signature-Generation/blob/main/src/DetectionBase/DetectionBase_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDFMyAxT-H9M"
      },
      "source": [
        "# **Train and Evaluate ML detection model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClU1LKe2A57d"
      },
      "source": [
        "# **Needed packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQHUGxAvA30L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da33db23-29ac-4d75-af93-9928ec1cdfd6"
      },
      "source": [
        "!pip install -U logzero"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting logzero\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/68/aa714515d65090fcbcc9a1f3debd5a644b14aad11e59238f42f00bd4b298/logzero-1.7.0-py2.py3-none-any.whl\n",
            "Installing collected packages: logzero\n",
            "Successfully installed logzero-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAuSv9yg7JZm"
      },
      "source": [
        "# **Set up Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDKmP0RC7Pyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd7b753-4237-4725-f513-d0fe132bc08e"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# set path where to mount drive\n",
        "drive_path = \"/content/drive\"\n",
        "\n",
        "# mount drive\n",
        "drive.mount(drive_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiCytUZjbFXq"
      },
      "source": [
        "# **Import needed modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106rYkMmbJdM"
      },
      "source": [
        "import torch  # Tensor library like NumPy, with strong GPU support\n",
        "from torch import nn  # a neural networks library deeply integrated with autograd designed for maximum flexibility\n",
        "import torch.nn.functional as F # pytorch neural network functional interface\n",
        "from torch.utils import data  # used to import data.Dataset -> we will subclass it; it will then be passed to data.Dataloader which is at the heart of PyTorch data loading utility\n",
        "import numpy as np # The fundamental package for scientific computing with Python\n",
        "import pandas as pd # Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool\n",
        "\n",
        "from copy import deepcopy # Used to construct a new compound object and then, recursively, insert copies into it of the objects found in the original\n",
        "from collections import defaultdict # Imports defaultdict from collections (which implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers)\n",
        "from sklearn.metrics import roc_auc_score # Used to compute the Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\n",
        "from sklearn.metrics import roc_curve # Used to compute the Receiver operating characteristic (ROC) curve\n",
        "\n",
        "import matplotlib # Comprehensive library for creating static, animated, and interactive visualizations in Python\n",
        "matplotlib.use('Agg') # Select 'Agg' as the backend used for rendering and GUI integration\n",
        "from matplotlib import pyplot as plt  # State-based interface to matplotlib, provides a MATLAB-like way of plotting\n",
        "\n",
        "import lmdb # Python binding for the LMDB ‘Lightning’ Database\n",
        "import sqlite3  # Provides a SQL interface compliant with the DB-API 2.0 specification\n",
        "import msgpack # Efficient binary serialization format\n",
        "import zlib # Allows compression and decompression, using the zlib library\n",
        "import json # JSON encoder and decoder\n",
        "import pickle # Implements binary protocols for serializing and de-serializing a Python object structure\n",
        "\n",
        "import warnings # Warning control module\n",
        "import sys  # System-specific parameters and functions\n",
        "import os # Provides a portable way of using operating system dependent functionality\n",
        "from multiprocessing import cpu_count # Used to get the number of CPUs in the system\n",
        "\n",
        "import tqdm # Instantly makes loops show a smart progress meter\n",
        "from logzero import logger # Robust and effective logging for Python"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDYdfgDHUzCL"
      },
      "source": [
        "# **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGwYEDyEUy2Z"
      },
      "source": [
        "class Config(object):\n",
        "    # NOTE -- if you change the \"validation_test_split\" and/or \"train_validation_split\" values, your results will not\n",
        "    #         be comparable with those from other users of this data set.\n",
        "\n",
        "    def __init__(self,\n",
        "                 db_path, # path to the directory that contains the meta_db\n",
        "                 checkpoint_dir, # path where to save the model training checkpoints to\n",
        "                 runs = 5,  # how many times to run the model (training + evaluation) to plot mean and confidence of the results\n",
        "                 device = 'cuda:0', # set this to the desired device, e.g. 'cuda:0' if a GPU is available, 'cpu' otherwise\n",
        "                 validation_test_split = 1547279640.0,  # timestamp that divides the validation data (used to check convergence/overfitting) from test data (used to assess final performance)\n",
        "                 train_validation_split = 1543542570.0, # timestamp that splits training data from validation data\n",
        "                 batch_size = 8192):  # Dataloader batch size (change as needed given memory/bus constraints)\n",
        "      \n",
        "        self.device = device\n",
        "        self.validation_test_split = validation_test_split\n",
        "        self.train_validation_split = train_validation_split\n",
        "        self.db_path = db_path\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.runs = runs\n",
        "\n",
        "        # create directory path if it does not exist (it succeeds even if the directory already exists)\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# instantiate configuration object\n",
        "config = Config(db_path = drive_path + \"/MyDrive/thesis/Dataset/09-DEC-2020/processed-data\",\n",
        "                checkpoint_dir = drive_path + \"/MyDrive/thesis/Checkpoints/\",\n",
        "                runs = 2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7H7Bf7TUkQO"
      },
      "source": [
        "# **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j9_dp5oUOkW"
      },
      "source": [
        "class LMDBReader(object): # lmdb (lightning database) reader\n",
        "\n",
        "    def __init__(self,\n",
        "                 path,  # Location of lmdb database\n",
        "                 postproc_func = None): # post processing function to apply to data points\n",
        "\n",
        "        # open the lmdb (lightning database) -> the result is an open lmdb environment\n",
        "        self.env = lmdb.open(path, # Location of directory\n",
        "                             readonly = True, # Disallow any write operations\n",
        "                             map_size = 1e13, # Maximum size database may grow to; used to size the memory mapping\n",
        "                             max_readers = 1024)  # Maximum number of simultaneous read transactions\n",
        "        \n",
        "        # set self data post processing function\n",
        "        self.postproc_func = postproc_func\n",
        "\n",
        "    def __call__(self,\n",
        "                 key):  # key (sha256) of the data point to retrieve\n",
        "\n",
        "        # Execute a transaction on the database\n",
        "        with self.env.begin() as txn:\n",
        "            x = txn.get(key.encode('ascii')) # Fetch the first value matching key (encoded in ascii)\n",
        "\n",
        "        if x is None: return None  # is no value was found matching key then return None\n",
        "        # otherwise decompress the (x) bytes, returning a bytes object containing\n",
        "        # the uncompressed data (x) and unpack it (from msgpack's array) to Python's list\n",
        "        x = msgpack.loads(zlib.decompress(x), strict_map_key=False)\n",
        "\n",
        "        if self.postproc_func is not None: # if the data post processing function was defined\n",
        "            x = self.postproc_func(x) # apply post processing function on the data point\n",
        "            \n",
        "        return x  # return the data point\n",
        "\n",
        "\n",
        "def features_postproc_func(x):  # data point to apply the post processing function to\n",
        "\n",
        "    x = np.asarray(x[0], dtype=np.float32) # Convert the input (x[0]) to a numpy array of float32\n",
        "    lz = x < 0  # create a numpy array of boolean -> lz[i] is true when x[i] < 0\n",
        "    gz = x > 0  # create a numpy array of boolean -> lz[i] is true when x[i] > 0\n",
        "    x[lz] = - np.log(1 - x[lz]) # if lz[i] is true -> assign x[i] = -np.log(1-x[i])\n",
        "    x[gz] = np.log(1 + x[gz])   # if gz[i] is true -> assign x[i] = np.log(1+x[i])\n",
        "    return x\n",
        "\n",
        "\n",
        "def tags_postproc_func(x):  # data point to apply the post processing function to\n",
        "\n",
        "    x = list(x[b'labels'].values()) # return datapoint labels as a list of labels\n",
        "    x = np.asarray(x) # transform list to a numpy array of labels\n",
        "    return x\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "\n",
        "    # list of malware tags\n",
        "    tags = [\"adware\", \"flooder\", \"ransomware\", \"dropper\", \"spyware\", \"packed\",\n",
        "            \"crypto_miner\", \"file_infector\", \"installer\", \"worm\", \"downloader\"]\n",
        "\n",
        "    def __init__(self,\n",
        "                 metadb_path, \t# path to the metadb (sqlite3 database containing index, labels, tags, and counts for the data)\n",
        "                 features_lmdb_path,  # path to the features lmbd (database containing the data features)\n",
        "                 return_malicious = True, # wether to return the malicious label for the data point or not\n",
        "                 return_counts = True,  # wether to return the counts for the data point or not\n",
        "                 return_tags = True,  # wether to return the tags for the data points or not\n",
        "                 return_shas = False, # wether to return the sha256 of the data points or not\n",
        "                 mode = 'train',  # mode of use of the dataset object (may be 'train', 'validation' or 'test')\n",
        "                 binarize_tag_labels = True,  # wether to binarize or not the tag values\n",
        "                 n_samples = None,  # maximum number of data points to consider (None if you want to consider them all)\n",
        "                 remove_missing_features = True,  # wether to remove data points with missing features or not; it can be False/None/'scan'/filepath\n",
        "                                                # in case it is 'scan' a scan will be performed on the database in order to remove the data points with missing features\n",
        "                                                # in case it is a filepaht then a file (in Json format) will be used to determine the data points with missing features\n",
        "                 postprocess_function = features_postproc_func):  # post processing function to use on each data point\n",
        "\n",
        "        # set some attributes\n",
        "        self.return_counts = return_counts\n",
        "        self.return_tags = return_tags\n",
        "        self.return_malicious = return_malicious\n",
        "        self.return_shas = return_shas\n",
        "\n",
        "        # define a lmdb reader with the features lmbd path (LMDB directory with baseline features) and post processing function\n",
        "        self.features_lmdb_reader = LMDBReader(features_lmdb_path,\n",
        "                                               postproc_func = postprocess_function)\n",
        "\n",
        "\n",
        "        retrieve = [\"sha256\"] # initialize list of strings with \"sha256\"\n",
        "\n",
        "        if return_malicious:\n",
        "            retrieve += [\"is_malware\"]  # add to the list of strings \"is_malware\"\n",
        "\n",
        "        if return_counts: \n",
        "            retrieve += [\"rl_ls_const_positives\"] # add to the list of strings \"rl_ls_const_positives\"\n",
        "\n",
        "        if return_tags:\n",
        "            retrieve.extend(Dataset.tags) # adds all the elements of tags list (iterable) to the end of the list of strings\n",
        "\n",
        "        conn = sqlite3.connect(metadb_path) # connect to the sqlite3 database containing index, labels, tags, and counts for the data\n",
        "        cur = conn.cursor() # create a cursor object for the db\n",
        "\n",
        "        # create SQL query\n",
        "        query = 'select ' + ','.join(retrieve)  # concatenate stringsf from the previously define list of strings with ','\n",
        "        query += \" from meta\"\n",
        "\n",
        "        # if in training select all data points before train_validation_split timestamp\n",
        "        if mode == 'train':\n",
        "            query += ' where(rl_fs_t <= {})'.format(config.train_validation_split)\n",
        "\n",
        "        # if in validation select all data points between two timestamps (train_validation_split and validation_test_split)\n",
        "        elif mode == 'validation':\n",
        "            query += ' where((rl_fs_t >= {}) and (rl_fs_t < {}))'.format(config.train_validation_split, config.validation_test_split)\n",
        "        \n",
        "        # if in test select all data points after validation_test_split timestamp\n",
        "        elif mode == 'test':\n",
        "            query += ' where(rl_fs_t >= {})'.format(config.validation_test_split)\n",
        "\n",
        "        # else provide an error\n",
        "        else:\n",
        "            raise ValueError('invalid mode: {}'.format(mode))\n",
        "\n",
        "        # log info\n",
        "        logger.info('Opening Dataset at {} in {} mode.'.format(metadb_path, mode))\n",
        "\n",
        "        # if n_samples is not None then limit the query to output a maximum of n_samples rows\n",
        "        if type(n_samples) != type(None):\n",
        "            query += ' limit {}'.format(n_samples)\n",
        "\n",
        "        vals = cur.execute(query).fetchall()  # execute the SQL query and fetch all results as a list\n",
        "        conn.close()  # close database connection\n",
        "\n",
        "        # log info\n",
        "        logger.info(f\"{len(vals)} samples loaded.\")\n",
        "\n",
        "        # map the items we're retrieving to an index (e.g. {'sha256': 0, 'is_malware': 1, ...})\n",
        "        retrieve_ind = dict(zip(retrieve, list(range(len(retrieve)))))\n",
        "\n",
        "        if remove_missing_features == 'scan': # if remove_missing_features is equal to the keyword 'scan'\n",
        "            # log info\n",
        "            logger.info(\"Removing samples with missing features...\")\n",
        "\n",
        "            indexes_to_remove = []  # initialize list of indexes to remove\n",
        "\n",
        "            # log info\n",
        "            logger.info(\"Checking dataset for keys with missing features.\")\n",
        "            \n",
        "            # open the lmdb (lightning database) -> the result is an open lmdb environment\n",
        "            temp_env = lmdb.open(features_lmdb_path,  # Location of directory\n",
        "                                 readonly = True, # Disallow any write operations\n",
        "                                 map_size = 1e13, # Maximum size database may grow to; used to size the memory mapping\n",
        "                                 max_readers = 256) # Maximum number of simultaneous read transactions\n",
        "            \n",
        "            # Execute a transaction on the database\n",
        "            with temp_env.begin() as txn:\n",
        "                # perform a loop -> for index, item in decorated iterator over samples (from metadb)\n",
        "                for index, item in tqdm.tqdm(enumerate(vals), # Iterable to decorate with a progressbar\n",
        "                                             total = len(vals), # The number of expected iterations\n",
        "                                             mininterval = .5,  # Minimum progress display update interval seconds\n",
        "                                             smoothing = 0.): # Exponential moving average smoothing factor for speed estimates\n",
        "                  \n",
        "                    # if in the features lmbd no element with the specified sha256 (got by metadb item) is found\n",
        "                    if txn.get(item[retrieve_ind['sha256']].encode('ascii')) is None:\n",
        "                        indexes_to_remove.append(index) # add index to the list of indexes to remove\n",
        "\n",
        "            indexes_to_remove = set(indexes_to_remove)  # create a set from list (duplicate values will be ignored)\n",
        "\n",
        "            # remove from vals all the items that are in indexes_to_remove set\n",
        "            vals = [value for index, value in enumerate(vals) if index not in indexes_to_remove]\n",
        "\n",
        "            # log info\n",
        "            logger.info(f\"{len(indexes_to_remove)} samples had no associated feature and were removed.\")\n",
        "            logger.info(f\"Dataset now has {len(vals)} samples.\")\n",
        "\n",
        "        elif (remove_missing_features is False) or (remove_missing_features is None):\n",
        "            pass  # NOP\n",
        "\n",
        "        else:\n",
        "            # assume remove_missing_features is a filepath\n",
        "\n",
        "            # log info\n",
        "            logger.info(f\"Trying to load shas to ignore from {remove_missing_features}...\")\n",
        "\n",
        "            # open file in read mode\n",
        "            with open(remove_missing_features, 'r') as f:\n",
        "                shas_to_remove = json.load(f) # deserialize from Json object to python object\n",
        "            shas_to_remove = set(shas_to_remove)  # create a set from list (duplicate values will be ignored)\n",
        "\n",
        "            # remove from vals all the items that are in indexes_to_remove set\n",
        "            vals = [value for value in vals if value[retrieve_ind['sha256']] not in shas_to_remove]\n",
        "\n",
        "            #log info\n",
        "            logger.info(f\"Dataset now has {len(vals)} samples.\")\n",
        "\n",
        "        # create a list of keys (sha256) from vals\n",
        "        self.keylist = list(map(lambda x: x[retrieve_ind['sha256']], vals))\n",
        "\n",
        "        if self.return_malicious:\n",
        "            # create a list of labels from vals\n",
        "            self.labels = list(map(lambda x: x[retrieve_ind['is_malware']], vals))\n",
        "\n",
        "        if self.return_counts:\n",
        "            # retrieve the list of counts from vals\n",
        "            self.count_labels = list(map(lambda x: x[retrieve_ind['rl_ls_const_positives']], vals))\n",
        "\n",
        "        if self.return_tags:\n",
        "            # create a numpy array of lists of tags from vals\n",
        "            self.tag_labels = np.asarray([list(map(lambda x: x[retrieve_ind[t]], vals)) for t in Dataset.tags]).T # Convert the input (list of tags per val in vals) to a nunpy array and get the transpose (.T)\n",
        "\n",
        "            if binarize_tag_labels:\n",
        "                # binarize the tag labels -> if the tag is different from 0 then it is set 1, otherwise it is set to 0\n",
        "                self.tag_labels = (self.tag_labels != 0).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.keylist)  # return the total number of samples\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    index): # index of the item to get\n",
        "\n",
        "        labels = {} # initialize labels set for this particular sample\n",
        "        key = self.keylist[index] # get sha256 key associated to this index\n",
        "        features = self.features_lmdb_reader(key) # get feature vector associated to this sample sha256\n",
        "\n",
        "        if self.return_malicious:\n",
        "            labels['malware'] = self.labels[index]  # get malware label for this sample through the index\n",
        "\n",
        "        if self.return_counts:\n",
        "            labels['count'] = self.count_labels[index]  # get count for this sample through the index\n",
        "\n",
        "        if self.return_tags:\n",
        "            labels['tags'] = self.tag_labels[index] # get tags list for this sample through the index\n",
        "\n",
        "        if self.return_shas:\n",
        "            return key, features, labels  # return sha256, features and labels associated to the sample with index 'index'\n",
        "        else:\n",
        "            return features, labels # return features and labels associated to the sample with index 'index'\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CULl7MoGUoK0"
      },
      "source": [
        "# **Define Generator (Dataloader)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iGfZeBjVGPF"
      },
      "source": [
        "# set max_workers to be equal to the current system cpu_count\n",
        "max_workers = cpu_count()\n",
        "\n",
        "\n",
        "class GeneratorFactory(object):\n",
        "\n",
        "    def __init__(self,\n",
        "                 ds_root, # path of the directory where to find the meta.db and ember_features files\n",
        "                 batch_size = None, # how many samples per batch to load\n",
        "                 mode = 'train',  # mode of use of the dataset object (may be 'train', 'validation' or 'test')\n",
        "                 num_workers = max_workers, # how many subprocesses to use for data loading by the Dataloader\n",
        "                 use_malicious_labels = False,  # wether to return the malicious label for the data points or not\n",
        "                 use_count_labels = False,  # wether to return the counts for the data points or not\n",
        "                 use_tag_labels = False,  # wether to return the tags for the data points or not\n",
        "                 return_shas = False, # wether to return the sha256 of the data points or not\n",
        "                 features_lmdb = 'ember_features',  # name of the file containing the ember_features for the data\n",
        "                 remove_missing_features = 'scan',  # wether to remove data points with missing features or not; it can be False/None/'scan'/filepath\n",
        "                                                  # in case it is 'scan' a scan will be performed on the database in order to remove the data points with missing features\n",
        "                                                  # in case it is a filepaht then a file (in Json format) will be used to determine the data points with missing features\n",
        "                 shuffle = None): # set to True to have the data reshuffled at every epoch\n",
        "      \n",
        "        # if mode is not in one of the expected values raise an exception\n",
        "        if mode not in {'train', 'validation', 'test'}:\n",
        "            raise ValueError('invalid mode {}'.format(mode))\n",
        "\n",
        "        # define Dataset object pointing to the dataset databases (meta.db and ember_features)\n",
        "        ds = Dataset(metadb_path = os.path.join(ds_root, 'meta.db'),  # join dataset_root path with the common name for the meta_db\n",
        "                     features_lmdb_path = os.path.join(ds_root,\n",
        "                                                     features_lmdb),  # join dataset_root path with the name of the file containing the ember_features\n",
        "                     return_malicious = use_malicious_labels,\n",
        "                     return_counts = use_count_labels,\n",
        "                     return_tags = use_tag_labels,\n",
        "                     return_shas = return_shas,\n",
        "                     mode = mode,\n",
        "                     remove_missing_features = remove_missing_features)\n",
        "        \n",
        "        # if the batch size was not defined (it was None) then set it to a default value of 1024\n",
        "        if batch_size is None:\n",
        "            batch_size = 1024\n",
        "        \n",
        "        # check passed-in value for shuffle; if it is not None it has to be either True or False\n",
        "        if shuffle is not None:\n",
        "            if not ( (shuffle is True) or (shuffle is False)):\n",
        "                raise ValueError(f\"'shuffle' should be either True or False, got {shuffle}\")\n",
        "        else:\n",
        "            # if it is None then if mode of use is 'train' then set shuffle to True, otherwise to false\n",
        "            if mode == 'train': shuffle = True\n",
        "            else: shuffle = False\n",
        "\n",
        "        # set up the parameters of the Dataloder\n",
        "        params = {'batch_size': batch_size,\n",
        "                  'shuffle': shuffle,\n",
        "                  'num_workers': num_workers}\n",
        "\n",
        "        # create Dataloader for the previously created dataset (ds) with the just specified parameters\n",
        "        self.generator = data.DataLoader(ds, **params)\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.generator\n",
        "\n",
        "\n",
        "def get_generator(mode, # mode of use of the dataset object (may be 'train', 'validation' or 'test')\n",
        "                  path = config.db_path,  # path of the directory where to find the meta.db and ember_features files\n",
        "                  use_malicious_labels = True,  # wether to return the malicious label for the data points or not\n",
        "                  use_count_labels = True,  # wether to return the counts for the data points or not\n",
        "                  use_tag_labels = True,  # wether to return the tags for the data points or not\n",
        "                  batch_size = config.batch_size, # how many samples per batch to load\n",
        "                  return_shas = False,  # wether to return the sha256 of the data points or not\n",
        "                  remove_missing_features = 'scan', # wether to remove data points with missing features or not; it can be False/None/'scan'/filepath\n",
        "                                                  # in case it is 'scan' a scan will be performed on the database in order to remove the data points with missing features\n",
        "                                                  # in case it is a filepaht then a file (in Json format) will be used to determine the data points with missing features\n",
        "                  num_workers = None, # how many subprocesses to use for data loading by the Dataloader\n",
        "                  shuffle = None, # set to True to have the data reshuffled at every epoch\n",
        "                  feature_lmdb = 'ember_features'): # name of the file containing the ember_features for the data\n",
        "  \n",
        "    # if num_workers was not defined (it is None) then set it to the maximum number of workers previously defined as the current system cpu_count\n",
        "    if num_workers is None:\n",
        "        num_workers = max_workers\n",
        "\n",
        "    # return the Generator (a.k.a. Dataloader)\n",
        "    return GeneratorFactory(path,\n",
        "                            batch_size = batch_size,\n",
        "                            mode = mode,\n",
        "                            num_workers = num_workers,\n",
        "                            use_malicious_labels = use_malicious_labels,\n",
        "                            use_count_labels = use_count_labels,\n",
        "                            use_tag_labels = use_tag_labels,\n",
        "                            return_shas = return_shas,\n",
        "                            remove_missing_features = remove_missing_features,\n",
        "                            shuffle = shuffle,\n",
        "                            features_lmdb = feature_lmdb)()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcwVwvH6VL8U"
      },
      "source": [
        "# **Define Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJeFtPyWVNxz"
      },
      "source": [
        "class PENetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a simple network loosely based on the one used in ALOHA: Auxiliary Loss Optimization for Hypothesis Augmentation (https://arxiv.org/abs/1903.05700)\n",
        "    Note that it uses fewer (and smaller) layers, as well as a single layer for all tag predictions, performance will suffer accordingly.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 use_malware = True,  # wether to use the malicious label for the data points or not\n",
        "                 use_counts = True, # wether to use the counts for the data points or not\n",
        "                 use_tags = True, # wether to use the tags for the data points or not\n",
        "                 n_tags = None, # number of tags to predict\n",
        "                 feature_dimension = 1024,  # dimension of the input data feature vector\n",
        "                 layer_sizes = None): # layer sizes (array of sizes)\n",
        "      \n",
        "        # set some attributes\n",
        "        self.use_malware = use_malware\n",
        "        self.use_counts = use_counts\n",
        "        self.use_tags = use_tags\n",
        "        self.n_tags = n_tags\n",
        "\n",
        "        if self.use_tags and self.n_tags == None: # if we set to use tags but n_tags was None raise an exception\n",
        "            raise ValueError(\"n_tags was None but we're trying to predict tags. Please include n_tags\")\n",
        "\n",
        "        #super(PENetwork,self).__init__()\n",
        "        super().__init__()  # call __init__() method of nn.Module\n",
        "\n",
        "        # set dropout probability\n",
        "        p = 0.05\n",
        "\n",
        "        layers = [] # initialize layers array\n",
        "\n",
        "        # if layer_sizes was not defined (it is None) then initialize it to a default of [512, 512, 128]\n",
        "        if layer_sizes is None: layer_sizes = [512, 512, 128]\n",
        "\n",
        "        # for each layer size in layer_sizes\n",
        "        for i, ls in enumerate(layer_sizes):\n",
        "            if i == 0:\n",
        "                layers.append(nn.Linear(feature_dimension, ls)) # append the first Linear Layer with dimensions feature_dimension x ls\n",
        "            else:\n",
        "                layers.append(nn.Linear(layer_sizes[i-1], ls))  # append a Linear Layer with dimensions layer_sizes[i-1] x ls\n",
        "\n",
        "            layers.append(nn.LayerNorm(ls)) # append a Norm layer of size ls\n",
        "            layers.append(nn.ELU()) # append an ELU activation function module\n",
        "            layers.append(nn.Dropout(p))  # append a dropout layer with probability of dropout p\n",
        "\n",
        "        self.model_base = nn.Sequential(*tuple(layers)) # create a tuple from the layers list, then apply nn.Sequential to get a sequential container -> this will be the model base\n",
        "        \n",
        "        # create malware/benign labeling head\n",
        "        self.malware_head = nn.Sequential(nn.Linear(layer_sizes[-1], 1),  # append a Linear Layer with size layer_sizes[-1] x 1\n",
        "                                          nn.Sigmoid()) # append a sigmoid activation function module\n",
        "        \n",
        "        # create count poisson regression head\n",
        "        self.count_head = nn.Linear(layer_sizes[-1], 1) # append a Linear Layer with size layer_sizes[-1] x 1\n",
        "\n",
        "        # sigmoid activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # create a tag multi-label classifting head\n",
        "        self.tag_head = nn.Sequential(nn.Linear(layer_sizes[-1], 64),  # append a Linear Layer with size layer_sizes[-1] x 64\n",
        "                                      nn.ELU(), # append an ELU activation function module\n",
        "                                      nn.Linear(64, 64),  # append a Linear Layer with size 64 x 64\n",
        "                                      nn.ELU(), # append an ELU activation function module\n",
        "                                      nn.Linear(64, n_tags), # append a Linear Layer with size 64 x n_tags\n",
        "                                      nn.Sigmoid()) # append a sigomid activation function module\n",
        "\n",
        "    def forward(self,\n",
        "                data):  # current batch of data (features)\n",
        "      \n",
        "        rv = {} # initialize return value\n",
        "\n",
        "        base_result = self.model_base.forward(data) # get base result forwarding the data through the base model\n",
        "\n",
        "        if self.use_malware:\n",
        "            rv['malware'] = self.malware_head(base_result)  # append to return value the result of the malware head\n",
        "\n",
        "        if self.use_counts:\n",
        "            rv['count'] = self.count_head(base_result)  # append to return value the result of the count head\n",
        "\n",
        "        if self.use_tags:\n",
        "            rv['tags'] = self.tag_head(base_result) # append to return value the result of the tag head\n",
        "\n",
        "        return rv # return the return value"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57HCdFmVT5M"
      },
      "source": [
        "# **Train Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcbUAgwCPYAL"
      },
      "source": [
        "## **Define training fuinction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp44KlycVVmQ"
      },
      "source": [
        "def compute_loss(predictions, # a dictionary of results from a PENetwork model\n",
        "                 labels,  # a dictionary of labels\n",
        "                 loss_wts = {'malware': 1.0,\n",
        "                             'count': 0.1,\n",
        "                             'tags': 0.1}): # weights to assign to each head of the network (if it exists)\n",
        "    \"\"\"\n",
        "    Compute losses for a malware feed-forward neural network (optionally with SMART tags \n",
        "    and vendor detection count auxiliary losses).\n",
        "    :param predictions: a dictionary of results from a PENetwork model\n",
        "    :param labels: a dictionary of labels \n",
        "    :param loss_wts: weights to assign to each head of the network (if it exists); defaults to \n",
        "        values used in the ALOHA paper (1.0 for malware, 0.1 for count and each tag)\n",
        "    \"\"\"\n",
        "    loss_dict = {'total':0.}  # initialize dictionary of losses\n",
        "\n",
        "    if 'malware' in labels: # if the malware head is enabled\n",
        "        # extract ground truth malware label, convert it to float and allocate it into the selected device (CPU or GPU)\n",
        "        malware_labels = labels['malware'].float().to(config.device)\n",
        "\n",
        "        # get predicted malware label, reshape it to the same shape of malware_labels\n",
        "        # then calculate binary cross entropy loss with respect to the ground truth malware labels\n",
        "        malware_loss = F.binary_cross_entropy(predictions['malware'].reshape(malware_labels.shape),\n",
        "                                              malware_labels)\n",
        "\n",
        "        # get loss weight (or set to default if not provided)\n",
        "        weight = loss_wts['malware'] if 'malware' in loss_wts else 1.0\n",
        "\n",
        "        # copy calculated malware loss into the loss dictionary\n",
        "        loss_dict['malware'] = deepcopy(malware_loss.item())\n",
        "\n",
        "        # update total loss\n",
        "        loss_dict['total'] += malware_loss * weight\n",
        "\n",
        "    if 'count' in labels: # if the count head is enabled\n",
        "        # extract ground truth count, convert it to float and allocate it into the selected device (CPU or GPU)\n",
        "        count_labels = labels['count'].float().to(config.device)\n",
        "\n",
        "        # get predicted count, reshape it to the same shape of count_labels\n",
        "        # then calculate poisson loss with respect to the ground truth count\n",
        "        count_loss = torch.nn.PoissonNLLLoss()(predictions['count'].reshape(count_labels.shape),\n",
        "                                               count_labels)\n",
        "\n",
        "        # get loss weight (or set to default if not provided)\n",
        "        weight = loss_wts['count'] if 'count' in loss_wts else 1.0\n",
        "\n",
        "        # copy calculated count loss into the loss dictionary\n",
        "        loss_dict['count'] = deepcopy(count_loss.item())\n",
        "\n",
        "        # update total loss\n",
        "        loss_dict['total'] += count_loss * weight\n",
        "\n",
        "    if 'tags' in labels:  # if the tags head is enabled\n",
        "        # extract ground truth tags, convert them to float and allocate them into the selected device (CPU or GPU)\n",
        "        tag_labels = labels['tags'].float().to(config.device)\n",
        "\n",
        "        # get predicted tags and then calculate binary cross entropy loss with respect to the ground truth tags\n",
        "        tags_loss = F.binary_cross_entropy(predictions['tags'],\n",
        "                                           tag_labels)\n",
        "\n",
        "        # get loss weight (or set to default if not provided)\n",
        "        weight = loss_wts['tags'] if 'tags' in loss_wts else 1.0\n",
        "\n",
        "        # copy calculated tags loss into the loss dictionary\n",
        "        loss_dict['tags'] = deepcopy(tags_loss.item())\n",
        "\n",
        "        # update total loss\n",
        "        loss_dict['total'] += tags_loss * weight\n",
        "\n",
        "    return loss_dict  # return the losses\n",
        "\n",
        "\n",
        "def train_network(train_db_path = config.db_path, # Path in which the meta.db is stored\n",
        "                  checkpoint_dir = config.checkpoint_dir, # Directory in which to save model checkpoints\n",
        "                  max_epochs = 10,  # How many epochs to train for\n",
        "                  use_malicious_labels = True,  # Whether or not to use malware/benignware labels as a target\n",
        "                  use_count_labels = True,  # Whether or not to use the counts as an additional target\n",
        "                  use_tag_labels = True,  # Whether or not to use SMART tags as additional targets\n",
        "                  feature_dimension = 2381, # The input dimension of the model\n",
        "                  random_seed = None, # if provided, seed random number generation with this value (defaults None, no seeding)\n",
        "                  workers = None, # How many worker processes should the dataloader use (if None use multiprocessing.cpu_count())\n",
        "                  remove_missing_features = 'scan'):  # Strategy for removing missing samples, with meta.db entries but no associated features, from the data\n",
        "                                                      # Must be one of: 'scan', 'none', or path to a missing keys file.  \n",
        "                                                      # Setting to 'scan' (default) will check all entries in the LMDB and remove any keys that are missing -- safe but slow. \n",
        "                                                      # Setting to 'none' will not perform a check, but may lead to a run failure if any features are missing.  Setting to\n",
        "                                                      # a path will attempt to load a json-serialized list of SHA256 values from the specified file, indicating which\n",
        "                                                      # keys are missing and should be removed from the dataloader.\n",
        "    \"\"\"\n",
        "    Train a feed-forward neural network on EMBER 2.0 features, optionally with additional targets as\n",
        "    described in the ALOHA paper (https://arxiv.org/abs/1903.05700).  SMART tags based on\n",
        "    (https://arxiv.org/abs/1905.06262)\n",
        "    \n",
        "    :param train_db_path: Path in which the meta.db is stored; defaults to the value specified in `config.py`\n",
        "    :param checkpoint_dir: Directory in which to save model checkpoints; WARNING -- this will overwrite any existing checkpoints without warning.\n",
        "    :param max_epochs: How many epochs to train for; defaults to 10\n",
        "    :param use_malicious_labels: Whether or not to use malware/benignware labels as a target; defaults to True\n",
        "    :param use_count_labels: Whether or not to use the counts as an additional target; defaults to True\n",
        "    :param use_tag_labels: Whether or not to use SMART tags as additional targets; defaults to True\n",
        "    :param feature_dimension: The input dimension of the model; defaults to 2381 (EMBER 2.0 feature size)\n",
        "    :param random_seed: if provided, seed random number generation with this value (defaults None, no seeding)\n",
        "    :param workers: How many worker processes should the dataloader use (default None, use multiprocessing.cpu_count())\n",
        "    :param remove_missing_features: Strategy for removing missing samples, with meta.db entries but no associated features,\n",
        "        from the data (e.g. feature extraction failures).  \n",
        "        Must be one of: 'scan', 'none', or path to a missing keys file.  \n",
        "        Setting to 'scan' (default) will check all entries in the LMDB and remove any keys that are missing -- safe but slow. \n",
        "        Setting to 'none' will not perform a check, but may lead to a run failure if any features are missing.  Setting to\n",
        "        a path will attempt to load a json-serialized list of SHA256 values from the specified file, indicating which\n",
        "        keys are missing and should be removed from the dataloader.\n",
        "    \"\"\"\n",
        "    # if workers has a value (it is not None) then convert it to int\n",
        "    workers = workers if workers is None else int(workers)\n",
        "\n",
        "    # create checkpoint directory\n",
        "    os.system('mkdir -p {}'.format(checkpoint_dir))\n",
        "\n",
        "    if random_seed is not None: # if a seed was provided\n",
        "        # log info\n",
        "        logger.info(f\"Setting random seed to {int(random_seed)}.\")\n",
        "        # set the seed for generating random numbers\n",
        "        torch.manual_seed(int(random_seed))\n",
        "\n",
        "    # log info\n",
        "    logger.info('...instantiating network')\n",
        "\n",
        "    # create malware-NN model and allocate it to the selected device (CPU or GPU)\n",
        "    model = PENetwork(use_malware = True,\n",
        "                      use_counts = True,\n",
        "                      use_tags = True,\n",
        "                      n_tags = len(Dataset.tags), # get n_tags counting tags from the dataset\n",
        "                      feature_dimension = feature_dimension).to(config.device)\n",
        "\n",
        "    # use Adam optimizer on all the model parameters \n",
        "    opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    # create generator (a.k.a. Dataloader)\n",
        "    generator = get_generator(path = train_db_path,\n",
        "                              mode = 'train', # select train mode\n",
        "                              use_malicious_labels = use_malicious_labels,\n",
        "                              use_count_labels = use_count_labels,\n",
        "                              use_tag_labels = use_tag_labels,\n",
        "                              num_workers = workers,\n",
        "                              remove_missing_features = remove_missing_features)\n",
        "    \n",
        "    # create validation generator (a.k.a. validation Dataloader)\n",
        "    val_generator = get_generator(path = train_db_path,\n",
        "                                  mode = 'validation',  # select validation mode\n",
        "                                  use_malicious_labels = use_malicious_labels,\n",
        "                                  use_count_labels = use_count_labels,\n",
        "                                  use_tag_labels = use_tag_labels,\n",
        "                                  num_workers = workers,\n",
        "                                  remove_missing_features = remove_missing_features)\n",
        "    \n",
        "    # get number of steps per epoch (# of total batches) from generator\n",
        "    steps_per_epoch = len(generator)\n",
        "    # get number of validation steps per epoch (# of total validation batches) from validation generator\n",
        "    val_steps_per_epoch = len(val_generator)\n",
        "\n",
        "    # loop for the selected number of epochs\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        # instantiate a new dictionary-like object called loss_histories\n",
        "        loss_histories = defaultdict(list)\n",
        "        # set the model mode to 'train'\n",
        "        model.train()\n",
        "\n",
        "        # for all the training batches\n",
        "        for i, (features, labels) in enumerate(generator):\n",
        "            opt.zero_grad() # clear old gradients from the last step\n",
        "\n",
        "            # copy current features and allocate them on the selected device (CPU or GPU)\n",
        "            features = deepcopy(features).to(config.device)\n",
        "\n",
        "            # perform a forward pass through the network\n",
        "            out = model(features)\n",
        "          \n",
        "            # compute loss given the predicted output from the model\n",
        "            loss_dict = compute_loss(out,\n",
        "                                     deepcopy(labels))  # copy the ground truth labels\n",
        "\n",
        "            # extract total loss                        \n",
        "            loss = loss_dict['total']\n",
        "\n",
        "            # compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # update model parameters\n",
        "            opt.step()\n",
        "\n",
        "            # for all the calculated losses in loss_dict\n",
        "            for k in loss_dict.keys():\n",
        "                # if the loss is 'total' then append it to loss_histories['total'] after having detached it and passed it to the cpu\n",
        "                if k == 'total': loss_histories[k].append(deepcopy(loss_dict[k].detach().cpu().item()))\n",
        "                # otherwise append the loss to loss_histories without having to detach it\n",
        "                else: loss_histories[k].append(loss_dict[k])\n",
        "\n",
        "            # create loss string with the current losses\n",
        "            loss_str = \" \".join([f\"{key} loss:{value:7.3f}\" for key, value in loss_dict.items()])\n",
        "            loss_str += \" | \"\n",
        "            loss_str += \" \".join([f\"{key} mean:{np.mean(value):7.3f}\" for key, value in loss_histories.items()])\n",
        "            # write on standard out the loss string + other information\n",
        "            sys.stdout.write('\\r Epoch: {}/{} {}/{} '.format(epoch, max_epochs, i + 1, steps_per_epoch) + loss_str)\n",
        "            # flush standard output\n",
        "            sys.stdout.flush()\n",
        "            del features, labels # to avoid weird references that lead to generator errors\n",
        "        \n",
        "        # save model in checkpoint dir\n",
        "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"epoch_{}.pt\".format(str(epoch))))\n",
        "        print()\n",
        "\n",
        "        # instantiate a new dictionary-like object called loss_histories\n",
        "        loss_histories = defaultdict(list)\n",
        "        # set the model mode to 'eval'\n",
        "        model.eval()\n",
        "\n",
        "        # for all the validation batches\n",
        "        for i, (features, labels) in enumerate(val_generator):\n",
        "            # copy current features and allocate them on the selected device (CPU or GPU)\n",
        "            features = deepcopy(features).to(config.device)\n",
        "\n",
        "            with torch.no_grad(): # disable gradient calculation\n",
        "                # perform a forward pass through the network\n",
        "                out = model(features)\n",
        "\n",
        "            # compute loss given the predicted output from the model\n",
        "            loss_dict = compute_loss(out,\n",
        "                                    deepcopy(labels)) # copy the ground truth labels\n",
        "            \n",
        "            # extract total loss \n",
        "            loss = loss_dict['total']\n",
        "\n",
        "            # for all the calculated losses in loss_dict\n",
        "            for k in loss_dict.keys():\n",
        "                # if the loss is 'total' then append it to loss_histories['total'] after having detached it and passed it to the cpu\n",
        "                if k == 'total': loss_histories[k].append(deepcopy(loss_dict[k].detach().cpu().item()))\n",
        "                # otherwise append the loss to loss_histories without having to detach it\n",
        "                else: loss_histories[k].append(loss_dict[k])\n",
        "\n",
        "             # create loss string with the current losses\n",
        "            loss_str = \" \".join([f\"{key} loss:{value:7.3f}\" for key, value in loss_dict.items()])\n",
        "            loss_str += \" | \"\n",
        "            loss_str += \" \".join([f\"{key} mean:{np.mean(value):7.3f}\" for key, value in loss_histories.items()])\n",
        "            # write on standard out the loss string + other information\n",
        "            sys.stdout.write('\\r   Val: {}/{} {}/{} '.format(epoch, max_epochs, i + 1, val_steps_per_epoch) + loss_str)\n",
        "            # flush standard output\n",
        "            sys.stdout.flush()\n",
        "            del features, labels # to avoid weird references that lead to generator errors\n",
        "        print() \n",
        "    print('...done')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbjlHl1EPTxW"
      },
      "source": [
        "## **Start training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrBOl2e3K9nv",
        "outputId": "ede0f9ed-3478-42b4-97bd-b1d15f89395e"
      },
      "source": [
        "# for the number of configured runs\n",
        "for i in range(config.runs):\n",
        "    # train network removing missing features using the 'shas_missing_ember_features.json' file\n",
        "    train_network(checkpoint_dir = config.checkpoint_dir + \"/\" + str(i),\n",
        "                  remove_missing_features = drive_path + \"/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/shas_missing_ember_features.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 210330 17:21:24 <ipython-input-8-faa596046a07>:122] ...instantiating network\n",
            "[I 210330 17:21:33 <ipython-input-5-eb915f5a92e0>:118] Opening Dataset at /content/drive/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/meta.db in train mode.\n",
            "[I 210330 17:22:30 <ipython-input-5-eb915f5a92e0>:128] 12908755 samples loaded.\n",
            "[I 210330 17:22:30 <ipython-input-5-eb915f5a92e0>:176] Trying to load shas to ignore from /content/drive/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/shas_missing_ember_features.json...\n",
            "[I 210330 17:22:34 <ipython-input-5-eb915f5a92e0>:187] Dataset now has 12699013 samples.\n",
            "[I 210330 17:23:06 <ipython-input-5-eb915f5a92e0>:118] Opening Dataset at /content/drive/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/meta.db in validation mode.\n",
            "[I 210330 17:23:17 <ipython-input-5-eb915f5a92e0>:128] 2544786 samples loaded.\n",
            "[I 210330 17:23:17 <ipython-input-5-eb915f5a92e0>:176] Trying to load shas to ignore from /content/drive/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/shas_missing_ember_features.json...\n",
            "[I 210330 17:23:18 <ipython-input-5-eb915f5a92e0>:187] Dataset now has 2495801 samples.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIfHj0MiVait"
      },
      "source": [
        "# **Evaluate Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX9wIOXDPb5g"
      },
      "source": [
        "## **Define evaluation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j2QXHuPVchK"
      },
      "source": [
        "# get tags from the dataset\n",
        "all_tags = Dataset.tags\n",
        "\n",
        "\n",
        "def detach_and_copy_array(array): # utility function to detach and (deep) copy an array\n",
        "    if isinstance(array, torch.Tensor): # if the provided array is of type Tensor\n",
        "        # return a copy of the array after having detached it, passed it to the cpu and finally flattened\n",
        "        return deepcopy(array.cpu().detach().numpy()).ravel()\n",
        "    elif isinstance(array, np.ndarray): # else if it is of type ndarray\n",
        "        # return a copy of the array after having flattened it\n",
        "        return deepcopy(array).ravel()\n",
        "    else:\n",
        "        # otherwise raise an exception\n",
        "        raise ValueError(\"Got array of unknown type {}\".format(type(array)))\n",
        "\n",
        "\n",
        "def normalize_results(labels_dict,  # (ground truth) labels dictionary\n",
        "                      results_dict, # results (predicted labels) dictionary\n",
        "                      use_malware=True, # Whether or not to use malware/benignware labels as a target\n",
        "                      use_count=True, # Whether or not to use the counts as an additional target\n",
        "                      use_tags=True): # Whether or not to use SMART tags as additional targets\n",
        "    \"\"\"\n",
        "    Take a set of results dicts and break them out into\n",
        "    a single dict of 1d arrays with appropriate column names\n",
        "    that pandas can convert to a DataFrame.\n",
        "    \"\"\"\n",
        "    # we do a lot of deepcopy stuff here to avoid a FD \"leak\" in the dataset generator\n",
        "    # see here: https://github.com/pytorch/pytorch/issues/973#issuecomment-459398189\n",
        "    \n",
        "    rv = {} # initialize return value dict\n",
        "\n",
        "    if use_malware: # if the malware/benign target label is enabled\n",
        "        # normalize malware ground truth label array and save it into rv\n",
        "        rv['label_malware'] = detach_and_copy_array(labels_dict['malware'])\n",
        "        # normalize malware predicted label array and save it into rv\n",
        "        rv['pred_malware'] = detach_and_copy_array(results_dict['malware'])\n",
        "\n",
        "    if use_count: # if the count additional target is enabled\n",
        "        # normalize ground truth count array and save it into rv\n",
        "        rv['label_count'] = detach_and_copy_array(labels_dict['count'])\n",
        "        # normalize predicted count array and save it into rv\n",
        "        rv['pred_count'] = detach_and_copy_array(results_dict['count'])\n",
        "\n",
        "    if use_tags:  # if the SMART tags additional targets are enabled\n",
        "        for column, tag in enumerate(all_tags): # for all the tags\n",
        "            # normalize ground truth tag array and save it into rv\n",
        "            rv[f'label_{tag}_tag'] = detach_and_copy_array(labels_dict['tags'][:, column])\n",
        "            # normalize predicted tag array and save it into rv\n",
        "            rv[f'pred_{tag}_tag'] = detach_and_copy_array(results_dict['tags'][:, column])\n",
        "\n",
        "    return rv\n",
        "\n",
        "\n",
        "def evaluate_network(results_dir, # The directory to which to write the 'results.csv' file\n",
        "                     checkpoint_file, # The checkpoint file containing the weights to evaluate\n",
        "                     db_path = config.db_path,  # The path to the directory containing the meta.db file\n",
        "                     evaluate_malware = True, # Whether or not to record malware labels and predictions\n",
        "                     evaluate_count = True, # Whether or not to record count labels and predictions\n",
        "                     evaluate_tags = True,  # Whether or not to record individual tag labels and predictions\n",
        "                     remove_missing_features = 'scan'): # Strategy for removing missing samples, with meta.db entries but no associated features, from the data\n",
        "                                                        # Must be one of: 'scan', 'none', or path to a missing keys file.  \n",
        "                                                        # Setting to 'scan' (default) will check all entries in the LMDB and remove any keys that are missing -- safe but slow. \n",
        "                                                        # Setting to 'none' will not perform a check, but may lead to a run failure if any features are missing.  Setting to\n",
        "                                                        # a path will attempt to load a json-serialized list of SHA256 values from the specified file, indicating which\n",
        "                                                        # keys are missing and should be removed from the dataloader.\n",
        "    \"\"\"\n",
        "    Take a trained feedforward neural network model and output evaluation results to a csv in the specified location.\n",
        "    :param results_dir: The directory to which to write the 'results.csv' file; WARNING -- this will overwrite any\n",
        "        existing results in that location\n",
        "    :param checkpoint_file: The checkpoint file containing the weights to evaluate\n",
        "    :param db_path: the path to the directory containing the meta.db file; defaults to the value in config.py\n",
        "    :param evaluate_malware: defaults to True; whether or not to record malware labels and predictions\n",
        "    :param evaluate_count: defaults to True; whether or not to record count labels and predictions\n",
        "    :param evaluate_tags: defaults to True; whether or not to record individual tag labels and predictions\n",
        "    :param remove_missing_features: See help for remove_missing_features in train.py / train_network\n",
        "    \"\"\"\n",
        "\n",
        "    # create result directory\n",
        "    os.system('mkdir -p {}'.format(results_dir))\n",
        "\n",
        "    # create malware-NN model\n",
        "    model = PENetwork(use_malware = True,\n",
        "                      use_counts = True,\n",
        "                      use_tags = True,\n",
        "                      n_tags = len(Dataset.tags), # get n_tags counting tags from the dataset\n",
        "                      feature_dimension = 2381)\n",
        "    \n",
        "    # load model parameters from checkpoint\n",
        "    model.load_state_dict(torch.load(checkpoint_file))\n",
        "\n",
        "    # allocate model to selected device (CPU or GPU)\n",
        "    model.to(config.device)\n",
        "\n",
        "    # create test generator (a.k.a. test Dataloader)\n",
        "    generator = get_generator(mode = 'test', # select test mode\n",
        "                              path = db_path,\n",
        "                              use_malicious_labels = evaluate_malware,\n",
        "                              use_count_labels = evaluate_count,\n",
        "                              use_tag_labels = evaluate_tags,\n",
        "                              return_shas = True, # return sha256 keys\n",
        "                              remove_missing_features = remove_missing_features)\n",
        "    \n",
        "    #log info\n",
        "    logger.info('...running network evaluation')\n",
        "\n",
        "    # create and open the results file in write mode\n",
        "    f = open(os.path.join(results_dir,'results.csv'),'w')\n",
        "\n",
        "    first_batch = True\n",
        "    # for all the batches in the generator (Dataloader)\n",
        "    for shas, features, labels in tqdm.tqdm(generator):\n",
        "        features = features.to(config.device)  # transfer features to selected device\n",
        "        predictions = model(features) # perform a forward pass through the network and get predictions\n",
        "        results = normalize_results(labels, predictions)  # normalize the results\n",
        "        \n",
        "        # store results into a pandas dataframe (indexed by the sha265 keys)\n",
        "        # and then save it as csv into file f (inserting the header only if this is the first batch in the loop)\n",
        "        pd.DataFrame(results, index=shas).to_csv(f, header=first_batch)\n",
        "\n",
        "        first_batch=False\n",
        "    f.close() #close results file\n",
        "    print('...done')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IR5zJZzPfzP"
      },
      "source": [
        "## **Start evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2D5Z9xeOS3d"
      },
      "source": [
        "#instantiate results_files dictionary\n",
        "results_files = {}\n",
        "\n",
        "# for the number of configured runs\n",
        "for i in range(config.runs):\n",
        "    # add file path to results_files dictionary (used for plotting results)\n",
        "    results_files[\"run_id_\" + str(i)] = drive_path + \"/MyDrive/thesis/Results/\" + str(i) + \"/results.csv\";\n",
        "\n",
        "    # evaluate network removing missing features using the 'shas_missing_ember_features.json' file\n",
        "    evaluate_network(results_dir = drive_path + \"/MyDrive/thesis/Results/\" + str(i),\n",
        "                     checkpoint_file = config.checkpoint_dir + \"/\" + str(i) + \"/epoch_10.pt\",\n",
        "                     remove_missing_features = drive_path + \"/MyDrive/thesis/Dataset/09-DEC-2020/processed-data/shas_missing_ember_features.json\")\n",
        "    \n",
        "# create and open the results.json file in write mode\n",
        "with open(drive_path + \"/MyDrive/thesis/Results/results.json\", \"w\") as output_file:\n",
        "    # save results_files dictionary as a json file\n",
        "    json.dump(results_files, output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nQYueE3Vg6M"
      },
      "source": [
        "# **Plot Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadR6lDTW4oE"
      },
      "source": [
        "## **Define plotting functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs9S4p6jViA0"
      },
      "source": [
        "# define default tags\n",
        "default_tags = ['adware_tag', 'flooder_tag', 'ransomware_tag',\n",
        "                'dropper_tag', 'spyware_tag', 'packed_tag',\n",
        "                'crypto_miner_tag', 'file_infector_tag', 'installer_tag',\n",
        "                'worm_tag', 'downloader_tag']\n",
        "\n",
        "# define default tag colors to be used in the graph\n",
        "default_tag_colors = ['r', 'r', 'r',\n",
        "                      'g', 'g', 'b',\n",
        "                      'b', 'm', 'm',\n",
        "                      'c', 'c']\n",
        "\n",
        "# define default tag linestyles to be used in the graph\n",
        "default_tag_linestyles = [':', '--', '-.',\n",
        "                          ':', '--', ':',\n",
        "                          '--', ':', '--',\n",
        "                          ':', '--']\n",
        "\n",
        "# combine the previously defined information into a \"style\" dictionary (e.g. {'adware_tag': ('r', ':'), ..})\n",
        "style_dict = {tag: (color, linestyle) for tag, color, linestyle in zip(default_tags,\n",
        "                                                                       default_tag_colors,\n",
        "                                                                       default_tag_linestyles)}\n",
        "\n",
        "# append style information for label 'malware'\n",
        "style_dict['malware'] = ('k', '-')\n",
        "\n",
        "\n",
        "def collect_dataframes(run_id_to_filename_dictionary):  # run ID - filename dictionary\n",
        "    # instantiate loaded_dataframes\n",
        "    loaded_dataframes = {}\n",
        "\n",
        "    #for each element in the run ID - filename dictionary\n",
        "    for k, v in run_id_to_filename_dictionary.items():\n",
        "        # read comma-separated values (csv) file into a DataFrame and save it into loaded dataframes dictionary\n",
        "        loaded_dataframes[k] = pd.read_csv(v)\n",
        "\n",
        "    return loaded_dataframes  # return all loaded dataframes\n",
        "\n",
        "\n",
        "def get_tprs_at_fpr(result_dataframe, # result dataframe for a certain run\n",
        "                    key,  # the name of the result to get the curve for\n",
        "                    target_fprs = None):  # The FPRs at which you wish to estimate the TPRs\n",
        "    \"\"\"\n",
        "    Estimate the True Positive Rate for a dataframe/key combination\n",
        "    at specific False Positive Rates of interest.\n",
        "    :param result_dataframe: a pandas dataframe\n",
        "    :param key: the name of the result to get the curve for; if (e.g.) the key 'malware' is provided\n",
        "    the dataframe is expected to have a column names `pred_malware` and `label_malware`\n",
        "    :param target_fprs: The FPRs at which you wish to estimate the TPRs; None (uses default np.array([1e-5, 1e-4, 1e-3, 1e-2, 1e-1]) or a 1-d numpy array\n",
        "    :return: target_fprs, the corresponsing TPRs\n",
        "    \"\"\"\n",
        "\n",
        "    # if target_fprs is not defined (it is None)\n",
        "    if target_fprs is None:\n",
        "        # set some defaults (numpy array)\n",
        "        target_fprs = np.array([1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
        "\n",
        "    # get ROC curve given the dataframe\n",
        "    fpr, tpr, thresholds = get_roc_curve(result_dataframe, key)\n",
        "\n",
        "    # return target_fprs and the intepolated values of the ROC curve (tpr/fpr) at points target_fprs\n",
        "    return target_fprs, np.interp(target_fprs, fpr, tpr)\n",
        "\n",
        "\n",
        "def get_roc_curve(result_dataframe, # result dataframe for a certain run\n",
        "                  key): # the name of the result to get the curve for\n",
        "    \"\"\"\n",
        "    Get the ROC curve for a single result in a dataframe\n",
        "    :param result_dataframe: a dataframe\n",
        "    :param key: the name of the result to get the curve for; if (e.g.) the key 'malware' is provided\n",
        "    the dataframe is expected to have a column names `pred_malware` and `label_malware`\n",
        "    :return: false positive rates, true positive rates, and thresholds (all np.arrays)\n",
        "    \"\"\"\n",
        "\n",
        "    # extract labels from result dataframe\n",
        "    labels = result_dataframe['label_{}'.format(key)]\n",
        "    # extract predictions from result dataframe\n",
        "    predictions = result_dataframe['pred_{}'.format(key)]\n",
        "\n",
        "    # return the ROC curve calculated given the labels and predictions\n",
        "    return roc_curve(labels, predictions)\n",
        "\n",
        "\n",
        "def get_auc_score(result_dataframe, # result dataframe for a certain run\n",
        "                  key): # the name of the result to get the curve for\n",
        "    \"\"\"\n",
        "    Get the Area Under the Curve for the indicated key in the dataframe\n",
        "    :param result_dataframe: a dataframe\n",
        "    :param key: the name of the result to get the curve for; if (e.g.) the key 'malware' is provided\n",
        "    the dataframe is expected to have a column names `pred_malware` and `label_malware`\n",
        "    :return: the AUC for the ROC generated for the provided key\n",
        "    \"\"\"\n",
        "\n",
        "    # extract labels from result dataframe\n",
        "    labels = result_dataframe['label_{}'.format(key)]\n",
        "    # extract predictions from result dataframe\n",
        "    predictions = result_dataframe['pred_{}'.format(key)]\n",
        "\n",
        "    # return the ROC AUC score given the labels and predictions\n",
        "    return roc_auc_score(labels, predictions)\n",
        "\n",
        "\n",
        "def interpolate_rocs(id_to_roc_dictionary,  # a list of results from get_roc_score (run ID - ROC curve dictionary)\n",
        "                     eval_fpr_points = None): # the set of FPR values at which to interpolate the results\n",
        "    \"\"\"\n",
        "    This function takes several sets of ROC results and interpolates them to a common set of\n",
        "    evaluation (FPR) values to allow for computing e.g. a mean ROC or pointwise variance of the curve\n",
        "    across multiple model fittings.\n",
        "    :param list_of_rocs: a list of results from get_roc_score (or sklearn.metrics.roc_curve) of the\n",
        "    form [(fpr_1, tpr_1, threshold_1), (fpr_2, tpr_2, threshold_2)...]\n",
        "    :param eval_fpr_points: the set of FPR values at which to interpolate the results; defaults to\n",
        "    `np.logspace(-6, 0, 1000)`\n",
        "    :return:\n",
        "        eval_fpr_points  -- the set of common points to which TPRs have been interpolated\n",
        "        interpolated_tprs -- an array with one row for each ROC provided, giving the interpolated TPR for that ROC at\n",
        "    the corresponding column in eval_fpr_points\n",
        "    \"\"\"\n",
        "\n",
        "    # if eval_frp_points was not defined (it is None)\n",
        "    if eval_fpr_points is None:\n",
        "        # set some default evaluation false positive rate points (fpr points)\n",
        "        eval_fpr_points = np.logspace(-6, 0, 1000)\n",
        "\n",
        "    # instantiate interpolated_tprs dictionary\n",
        "    interpolated_tprs = {}\n",
        "\n",
        "    # for all the runs\n",
        "    for k, (fpr, tpr, thresh) in id_to_roc_dictionary.items():\n",
        "        # interpolate ROC curve (tpr/fpr) at points eval_fpr_points\n",
        "        interpolated_tprs[k] = np.interp(eval_fpr_points, fpr, tpr)\n",
        "\n",
        "    # return the eval_fpr_points and interpolated_tprs\n",
        "    return eval_fpr_points, interpolated_tprs\n",
        "\n",
        "\n",
        "def plot_roc_with_confidence(id_to_dataframe_dictionary,  # run ID - result dataframe dictionary\n",
        "                             key, # the name of the result to get the curve for\n",
        "                             filename,  # The filename to save the resulting figure to\n",
        "                             include_range = False, # plot the min/max value as well\n",
        "                             style = None,  # style (color, linestyle) to use in the plot\n",
        "                             std_alpha = .2,  # the alpha value for the shading for standard deviation range\n",
        "                             range_alpha = .1): # the alpha value for the shading for range, if plotted\n",
        "    \"\"\"\n",
        "    Compute the mean and standard deviation of the ROC curve from a sequence of results\n",
        "    and plot it with shading.\n",
        "    \"\"\"\n",
        "\n",
        "    # if the length of the run ID - result dataframe dictionary is not grater than 1\n",
        "    if not len(id_to_dataframe_dictionary) > 1:\n",
        "        # raise an exception\n",
        "        raise ValueError(\"Need a minimum of 2 result sets to plot confidence region; found {}\".format(\n",
        "            len(id_to_dataframe_dictionary)\n",
        "        ))\n",
        "\n",
        "    # if the style was not defined (it is None)\n",
        "    if style is None:\n",
        "        # if the key is present inside style_dict then use a default style\n",
        "        if key in style_dict:\n",
        "            color, linestyle = style_dict[key]\n",
        "        else: # otherwise raise an exception\n",
        "            raise ValueError(\"No default style information is available for key {}; please provide (linestyle, color)\".format(key))\n",
        "\n",
        "    else: # otherwise (the style was defined)\n",
        "        linestyle, color = style  # get linestyle and color from style\n",
        "\n",
        "    # calculate ROC curve for each run and create a run ID - ROC curve dictionary\n",
        "    id_to_roc_dictionary = {k: get_roc_curve(df, key) for k, df in id_to_dataframe_dictionary.items()}\n",
        "    \n",
        "    # interpolate ROC curves and get fpr (false positive rate) points and interpolated tprs (true positive rates)\n",
        "    fpr_points, interpolated_tprs = interpolate_rocs(id_to_roc_dictionary)\n",
        "\n",
        "    # stack the interpolated_tprs arrays in sequence vertically -> I obtain a vertical vector of vectors (each of which has all the interpolated values for one single run)\n",
        "    tpr_array = np.vstack([v for v in interpolated_tprs.values()])\n",
        "\n",
        "    # calculate mean tpr along dim 0 -> (for each fpr point under examination I calculate the mean along all runs)\n",
        "    mean_tpr = tpr_array.mean(0)\n",
        "\n",
        "    # calculate tpr standard deviation by calculating the tpr variance along dim 0 and then calculating the square root\n",
        "    # -> (for each fpr point under examination I calculate the standard deviation along all runs)\n",
        "    std_tpr = np.sqrt(tpr_array.var(0))\n",
        "\n",
        "    # calculate AUC (area under (ROC) curve) score for each run and store them into a numpy array\n",
        "    aucs = np.array([get_auc_score(v, key) for v in id_to_dataframe_dictionary.values()])\n",
        "\n",
        "    # calculate the mean ROC AUC score along all runs\n",
        "    mean_auc = aucs.mean()\n",
        "    # caluclate the min value for the ROC AUC score along all runs\n",
        "    min_auc = aucs.min()\n",
        "    # caluclate the max value for the ROC AUC score alonf all runs\n",
        "    max_auc = aucs.max()\n",
        "    # caluclate the standard deviation for the ROC AUC score along all runs\n",
        "    # (by calculating the ROC AUC score variance and then taking the square root)\n",
        "    std_auc = np.sqrt(aucs.var())\n",
        "\n",
        "    # create a new figure of size 12 x 12\n",
        "    plt.figure(figsize = (12, 12))\n",
        "\n",
        "    # plot ROC curve\n",
        "    plt.semilogx( # make a plot with log scaling on the x axis\n",
        "        fpr_points, # false positive rate points as 'x' values\n",
        "        mean_tpr,  # mean true positive rates as 'y' values\n",
        "        color + linestyle, # format string, e.g. 'ro' for red circles\n",
        "        linewidth = 2.0, # line width in points\n",
        "        label = f\"{key}: {mean_auc:5.3f}$\\pm${std_auc:5.3f} [{min_auc:5.3f}-{max_auc:5.3f}]\")  # label that will be displayed in the legend\n",
        "    \n",
        "    # fill uncertainty area around ROC curve\n",
        "    plt.fill_between( # fill the area between two horizontal curves\n",
        "        fpr_points,  # false positive rate points as 'x' values\n",
        "        mean_tpr - std_tpr,  # mean - standard deviation of true positive rates as 'y' coordinates of the first curve\n",
        "        mean_tpr + std_tpr,  # mean + standard deviation of true positive rates as 'y' coordinates of the second curve\n",
        "        color = color, # set both the edgecolor and the facecolor\n",
        "        alpha = std_alpha) # set the alpha value used for blending\n",
        "    \n",
        "    # if the user wants to plot the min/max value as well\n",
        "    if include_range:\n",
        "        # fill area between min and max ROC curve values \n",
        "        plt.fill_between(# fill the area between two horizontal curves\n",
        "            fpr_points, # false positive rate points as 'x' values\n",
        "            tpr_array.min(0), # min true positive rates as 'y' coordinates of the first curve\n",
        "            tpr_array.max(0), # max true positive rates as 'y' coordinates of the second curve\n",
        "            color = color,  # set both the edgecolor and the facecolor\n",
        "            alpha = range_alpha)  # set the alpha value used for blending\n",
        "    \n",
        "    plt.legend()  # place legend on the axes\n",
        "    plt.xlim(1e-6, 1.0) # set the x plot limits\n",
        "    plt.ylim([0., 1.])  # set the y plot limits\n",
        "    plt.xlabel('False Positive Rate (FPR)') # set the label for the x-axis\n",
        "    plt.ylabel('True Positive Rate (TPR)')  # set the label for the y-axis\n",
        "    plt.savefig(filename) # save the current figure to file\n",
        "    plt.clf() # clear the current figure\n",
        "\n",
        "\n",
        "def plot_tag_results(dataframe, # run ID - result dataframe dictionary\n",
        "                     filename): # the name of the file in which to save the resulting plot\n",
        "  \n",
        "    # calculate ROC curve for each tag of the current (single) run and create a tag - ROC curve dictionary\n",
        "    all_tag_rocs = {tag: get_roc_curve(dataframe, tag) for tag in default_tags}\n",
        "\n",
        "    # interpolate ROC curves and get fpr (false positive rate) points and interpolated tprs (true positive rates)\n",
        "    eval_fpr_pts, interpolated_rocs = interpolate_rocs(all_tag_rocs)\n",
        "\n",
        "    # create a new figure of size 12 x 12\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    # for each tag\n",
        "    for tag in default_tags:\n",
        "        # use a default style\n",
        "        color, linestyle = style_dict[tag]\n",
        "        \n",
        "        # calculate AUC (area under (ROC) curve) score\n",
        "        auc = get_auc_score(dataframe, tag)\n",
        "\n",
        "        # plot ROC curve\n",
        "        plt.semilogx( # make a plot with log scaling on the x axis\n",
        "            eval_fpr_pts, # false positive rate points as 'x' values\n",
        "            interpolated_rocs[tag], # interpolated true positive rates for the current tag as 'y' values\n",
        "            color + linestyle,  # format string, e.g. 'ro' for red circles\n",
        "            linewidth = 2.0,  # line width in points\n",
        "            label = f\"{tag}:{auc:5.3f}\")  # label that will be displayed in the legend\n",
        "        \n",
        "    plt.legend(loc = 'best')  # place legend in the location, among the nine possible locations, with the minimum overlap with other drawn objects\n",
        "    plt.xlim(1e-6, 1.0) # set the x plot limits\n",
        "    plt.ylim([0., 1.])  # set the y plot limits\n",
        "    plt.xlabel('False Positive Rate (FPR)') # set the label for the x-axis\n",
        "    plt.ylabel('True Positive Rate (TPR)')  # set the label for the y-axis\n",
        "    plt.savefig(filename) # save the current figure to file\n",
        "    plt.clf() # clear the current figure\n",
        "\n",
        "\n",
        "def plot_tag_result(results_file, # complete path to a results.csv file that contains the output of a model run\n",
        "                    output_filename): # the name of the file in which to save the resulting plot\n",
        "    \"\"\"\n",
        "    Takes a result file from a feedforward neural network model that includes all\n",
        "    tags, and produces multiple overlaid ROC plots for each tag individually.\n",
        "    :param results_file: complete path to a results.csv file that contains the output of \n",
        "        a model run.  Note that the model must have been trained with --use_tag_labels=True\n",
        "        and evaluated using --evaluate_tags=True\n",
        "    :param output_filename: the name of the file in which to save the resulting plot.\n",
        "    \"\"\"\n",
        "\n",
        "    # create run ID - filename correspondence dictionary (containing just one result file)\n",
        "    id_to_resultfile_dict = {'run': results_file}\n",
        "\n",
        "    # read csv result file and obtain a run ID - result dataframe dictionary\n",
        "    id_to_dataframe_dict = collect_dataframes(id_to_resultfile_dict)\n",
        "\n",
        "    # produce multiple overlaid ROC plots (one for each tag individually) and save the overall figure to file\n",
        "    plot_tag_results(id_to_resultfile_dict['run'], output_filename)\n",
        "\n",
        "\n",
        "def plot_roc_distribution_for_tag(run_to_filename_json, #  A json file that contains a key-value map that links run IDs to the full path to a results file (including the file name)\n",
        "                                  output_filename,  # The filename to save the resulting figure to\n",
        "                                  tag_to_plot = 'malware',  # the tag from the results to plot\n",
        "                                  linestyle = None, # the linestyle to use in the plot (if None use some defaults)\n",
        "                                  color = None, # the color to use in the plot (if None use some defaults)\n",
        "                                  include_range = False,  # plot the min/max value as well\n",
        "                                  std_alpha = .2, # the alpha value for the shading for standard deviation range\n",
        "                                  range_alpha = .1):  # the alpha value for the shading for range, if plotted\n",
        "    \"\"\"\n",
        "    Compute the mean and standard deviation of the TPR at a range of FPRS (the ROC curve)\n",
        "    over several sets of results (at least 2 runs) for a given tag.  The run_to_filename_json file must have\n",
        "    the following format:\n",
        "    {\"run_id_0\": \"/full/path/to/results.csv/for/run/0/results.csv\",\n",
        "     \"run_id_1\": \"/full/path/to/results.csv/for/run/1/results.csv\",\n",
        "      ...\n",
        "    }\n",
        "    \n",
        "    :param run_to_filename_json: A json file that contains a key-value map that links run IDs to\n",
        "        the full path to a results file (including the file name)\n",
        "    :param output_filename: The filename to save the resulting figure to\n",
        "    :param tag_to_plot: the tag from the results to plot; defaults to \"malware\"\n",
        "    :param linestyle: the linestyle to use in the plot (defaults to the tag value in \n",
        "        plot.style_dict)\n",
        "    :param color: the color to use in the plot (defaults to the tag value in \n",
        "        plot.style_dict)\n",
        "    :param include_range: plot the min/max value as well (default False)\n",
        "    :param std_alpha: the alpha value for the shading for standard deviation range\n",
        "        (default 0.2)\n",
        "    :param range_alpha: the alpha value for the shading for range, if plotted\n",
        "        (default 0.1)\n",
        "    \"\"\"\n",
        "\n",
        "    # open json containing run ID - filename correspondeces and decode it as json object\n",
        "    id_to_resultfile_dict = json.load(open(run_to_filename_json, 'r'))\n",
        "\n",
        "    # read csv result files and obtain a run ID - result dataframe dictionary\n",
        "    id_to_dataframe_dict = collect_dataframes(id_to_resultfile_dict)\n",
        "\n",
        "    if color is None or linestyle is None: # if either color or linestyle is None\n",
        "        if not (color is None and linestyle is None): # if just one of them is None\n",
        "            raise ValueError(\"both color and linestyle should either be specified or None\") # raise an exception\n",
        "        \n",
        "        # otherwise select None as style\n",
        "        style = None\n",
        "\n",
        "    else:\n",
        "        # otherwise (both color and linestyle were specified) define the style as a tuple of color and linestyle\n",
        "        style = (color, linestyle)\n",
        "        \n",
        "    # plot roc curve with confidence\n",
        "    plot_roc_with_confidence(id_to_dataframe_dict,\n",
        "                             tag_to_plot,\n",
        "                             output_filename,\n",
        "                             include_range = include_range,\n",
        "                             style = style,\n",
        "                             std_alpha = std_alpha,\n",
        "                             range_alpha = range_alpha)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axJ1zrQUWzlL"
      },
      "source": [
        "## **Start plotting results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XjRp_UUPqaw"
      },
      "source": [
        "# for the number of configured runs\n",
        "for i in range(config.runs):\n",
        "    plot_tag_result(results_file = drive_path + \"/MyDrive/thesis/Results/\" + str(i) + \"results.csv\",\n",
        "                    output_filename = drive_path + \"/MyDrive/thesis/Results/\" + str(i) + \"results.png\")\n",
        "\n",
        "plot_roc_distribution_for_tag(run_to_filename_json = drive_path + \"/MyDrive/thesis/Results/results.json\",\n",
        "                              output_filename = drive_path + \"/MyDrive/thesis/Results/results.png\",\n",
        "                              tag_to_plot = 'malware')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}